# 📝 Natural Language Processing Specialization

### Coursera | DeepLearning.AI | 4-Course Series on NLP 🚀

This specialization dives deep into **Natural Language Processing (NLP)**—the convergence of linguistics, computer science, and AI—to transform raw text into actionable insights using **state-of-the-art algorithms**.

---

## 🌟 Key Takeaways:
- Master **sentiment analysis** and **question-answering** models.
- Build powerful tools for **language translation**, **text summarization**, and **chatbots**.
- Gain expertise in **machine learning** and **deep learning** techniques for NLP.

---

## 🏗️ Applied Projects Overview:
1. **Logistic Regression** & **Naïve Bayes**  
   _Sentiment analysis, analogy completion, language translation, and nearest neighbor search._
2. **Hidden Markov Models** & **Embeddings**  
   _Autocorrect, autocomplete, and part-of-speech (POS) tagging._
3. **RNNs**, **LSTMs**, **GRUs** & **Siamese Networks**  
   _Advanced text generation and duplicate question detection._
4. **Attention Mechanisms**:  
   _Create chatbots, perform question-answering, and explore BERT & Transformer models with 🤗._

---

## 🧑‍🏫 Taught by Industry Experts:
- **Younes Bensouda Mourri**  
  _Stanford AI Instructor & Co-creator of the Deep Learning Specialization._
- **Łukasz Kaiser**  
  _Google Brain Researcher, Co-author of Tensorflow, Tensor2Tensor, Trax, and the Transformer._

---


# 📒 Course 1: Natural Language Processing with Classification and Vector Spaces
![](Course_01_Certificate.jpg)

### 🛠️ What I Worked On:

1. **Sentiment Analysis with Logistic Regression & Naïve Bayes**  
   _Classified tweets to determine positive or negative sentiment using two classic ML techniques._  
   - **Sentiment Analysis**: Predict if a tweet has positive or negative sentiment.

2. **Vector Space Models & PCA for Word Relationships**  
   _Explored relationships between words using word embeddings and applied **PCA** to reduce dimensionality and visualize them._  
   - **PCA (Principal Component Analysis)**: Visualize relationships in lower-dimensional space.

3. **English-to-French Translation with Word Embeddings**  
   _Built a simple translation algorithm using pre-computed word embeddings and **locality-sensitive hashing** (LSH) for approximate k-nearest neighbor search._  
   - **Locality-Sensitive Hashing (LSH)**: Efficiently search for related words using k-NN search.

